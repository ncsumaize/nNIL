---
title: "SNP_info_nNILs"
author: "Jim Holland"
date: "2024-06-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(tidyverse)
library(vcfR)
base.path = "C:/Users/jholland/Box/nNIL genotype data Jim and Tao/"
```

# Founder HapMap Data 
Read in the founder HapMap SNPs in v3
```{r}
founderVCF = read.vcfR(paste0(base.path, "Data/nNIL_founders_consistent_gbsSNPs_v3.vcf.gz"), verbose = FALSE )
```

Get the info in v3 on each SNP, get the original ordering of SNPs in vcf
```{r}
founder_meta = founderVCF@fix
founder_meta = cbind(founder_meta, ord = 1:nrow(founder_meta))
```

Get the set of SNPs overlapping between nNIL gbs markers and HapMap3 markers with consistent REF/ALT alleles (identified in Step 4)
```{r}
consistentSNPs = read.csv(paste0(base.path, "Output/nNIL_gbs_SNPs_congruent_w_HapMap_v3v4v5coords_info.csv"))
```

Match the v3 position info with the v4 position info
```{r}
founder_meta_v4 = merge(founder_meta[,c("CHROM", "POS", "ord")], consistentSNPs, by.x = c("CHROM", "POS"), by.y = c("chrV3", "endV3")) %>%
  mutate(ord = as.numeric(ord)) %>%
  arrange(ord)
```

Verify the sorted V3 order matches the order of SNPs in founder matrix
```{r}
all(founder_meta_v4$POS == founder_meta[,"POS"])
```
Get the founder calls
```{r}
founder_calls =extract.gt(founderVCF, return.alleles = T)
founder_calls[founder_calls == "."] = NA
```

We verified above that the sorting of SNP names in founder_meta_v4 matches the founder VCF, so we can use the V4 SNP names to replace the V3 based row names.
```{r}
row.names(founder_calls) = founder_meta_v4$nameV4
colnames(founder_calls) = sub("282set_", "", colnames(founder_calls))
```

Convert the biallelic calls in founder_calls to single character IUPAC values, this is format used by the gbs_snp_v4 data frame.
```{r}
biallelic_to_IUPAC = function(x){
  if (is.na(x)) {return(x)}
  if (x == "A/A") {return("A")}
  if (x == "C/C") {return("C")}
  if (x == "G/G") {return("G")}
  if (x == "T/T") {return("T")}
  if (x == "A/C" | x == "C/A") {return("M")}
  if (x == "A/G" | x == "G/A") {return("R")}
  if (x == "A/T" | x == "T/A") {return("W")}
  if (x == "C/G" | x == "G/C") {return("S")}
  if (x == "C/T" | x == "T/C") {return("Y")}
  if (x == "G/T" | x == "T/G") {return("K")}
  return(NA) #in case no match
}
```

```{r}
founder_calls_iupac = apply(founder_calls, 1:2, biallelic_to_IUPAC)
```

# nNIL data

Get nNIL GBS SNPs in original V4 positions uplifted to V3 This is a subset after filtering to < 20% missing data in the vcf.
```{r}
gbs_v3 = read.table(paste0(base.path, "Data/nNIL_gbs_snps_converted_V3.bed"))
names(gbs_v3) = c("chrV3", "startV3", "endV3", "nameV4", "score", "strand")
gbs_v3 = gbs_v3 %>% separate(nameV4, into = c("chrV4", "posV4"), sep = "_", remove = F) %>%
  mutate(chrV4 = as.integer(sub("S", "", chrV4)))%>%
  select(-score, -strand)

```

Check GBS nNIL SNP info directly from hapmap meta data column alleles. Assuming first allele is reference
```{r}
gbs_snp_v4 = 
read.table(paste0(base.path,"Data/raw_snps_bgi_id.hmp.txt"), comment.char = "", header = T)
colnames(gbs_snp_v4)[1:4] = c("nameV4", "alleles", "chrV4", "posV4")
```

Now subset the GBS SNP calls on nNIL lines to the same set of SNPs. Make sure missing values of N are set to NA. Also a few rare values need to be set to missing
```{r}
gbs_snp_v4_consistent = gbs_snp_v4[gbs_snp_v4$nameV4 %in% row.names(founder_calls),]
gbs_snp_v4_consistent[gbs_snp_v4_consistent == "-"] = NA
gbs_snp_v4_consistent[gbs_snp_v4_consistent == "N"] = NA
gbs_snp_v4_consistent[gbs_snp_v4_consistent == "O"] = NA
```

change NIL line names from BGI codes to standard NIL line names
```{r}
name_translator = read.table(paste0(base.path, "Data/bgi_nil_id.txt"), sep = "\t", header = T, fileEncoding = "latin1")
name_translator = name_translator %>% 
  mutate(bgi_id = gsub("-", ".", bgi_id),
    nil_id = sub("B73.NIL", "B73 NIL", nil_id))
name_translator_vec = name_translator$nil_id
names(name_translator_vec) = name_translator$bgi_id
colnames(gbs_snp_v4_consistent)[12:ncol(gbs_snp_v4_consistent)] = name_translator_vec[colnames(gbs_snp_v4_consistent)[12:ncol(gbs_snp_v4_consistent)]]
```


Get the introgression calls on the nNILs
```{r}
intros = read.csv(paste0(base.path, "nNIL_data_supplement/File_S18.Individual_Introgressions_gbs.csv"))
```


Keep only NILs whose line names match the gbs line names
```{r}
intros_sub = intros |>
  filter(Line %in% colnames(gbs_snp_v4_consistent))
```


Finally, get the order of SNPs identical between founder_calls_iupac and gbs_snp_v4_consistent. Since the founder gbs and the nNIL gbs were aligned to different reference genomes, their ordering may vary and we need to make them identical
```{r}
all(rownames(founder_calls_iupac) == gbs_snp_v4_consistent$nameV4)
```
Resort the founder call SNPs to match nNILs. Need to parse the names into chrom and position to do this, then sort by NUMERIC chromosome and position
```{r}
founder_call_snps = strsplit(rownames(founder_calls_iupac), "_")
founder_call_snps = as.data.frame(do.call(rbind, founder_call_snps))
colnames(founder_call_snps) = c("chrV4", "posV4")
founder_call_snps$chrV4 = sub("S", "", founder_call_snps$chrV4)
founder_call_snps$nameV4 = rownames(founder_calls_iupac)
founder_calls_iupac = cbind(founder_call_snps, founder_calls_iupac)
founder_calls_iupac = as.data.frame(founder_calls_iupac) %>%
  mutate(chrV4 = as.numeric(chrV4),
         posV4 = as.numeric(posV4)) %>%
  arrange(chrV4, posV4)
```

Check that the new sorting matches the nNIL gbs marker order exactly
```{r}
all(founder_calls_iupac$nameV4 == gbs_snp_v4_consistent$nameV4)
```
Yay!!

Make a function to compute the proportion of base pair call matches between nNILs and founders within individual introgressions. 
Input is one row of the intros_sub data frame, defining the region of one introgression in one NIL.  
Output is a list with three components: the vector of match percentages against all NAM founders, the number of SNPs, and the percent homoz. calls in the introgression block.
NOTE THAT THERE ARE EDGE CASES WITH FEW, EVEN ZERO, SNPS IN COMMON BETWEEN SMALLER INTROGRESSION BLOCKS IN NILS AND THE FOUNDERS. SO SOME INTROGRESSIONS MAYE RETURN NA VALUES FOR SOME OR ALL FOUNDER MATCH RATES AND POSSIBLY ZERO MARKERS. Function will not fail, but will return NAs.
```{r}
compare_SNPs_in_intros_nohets = function(x){
  #x is one row of intros_sub data frame, becomes a character vector here
  #extract the column of chip SNP calls for the current NIL along with metadata cols 
  line_SNPcalls = gbs_snp_v4_consistent[,c('nameV4','chrV4', 'posV4', x['Line'])]
  #extract the markers defining the current introgression block
  selectMarkers = line_SNPcalls |> 
    filter((chrV4 == as.numeric(x['chr']))  & (posV4 >= as.numeric(x['pos_leftflank'])) & (posV4 <= as.numeric(x['pos_rightflank'])))
  #subset the current NILs SNP calls to only the current introgression
  line_SNPcalls_in_intro = unlist(selectMarkers[x['Line']])

  #subset the founder SNP calls to the same set of markers, dropping cols 1 - 3 of meta-data
  match_founders = founder_calls_iupac[selectMarkers$nameV4,-c(1:3)]
  #compute the match percentage, ignoring hets/NAs
  compare = apply(match_founders, 2, FUN = function(y) {sum(y == line_SNPcalls_in_intro, na.rm = T)/sum(!is.na(y) & !is.na(line_SNPcalls_in_intro))})
  #also compute the number of SNPs NOT missing (not hets)
  N.homoz = sum(!is.na(line_SNPcalls_in_intro))
  return(list(compare, nrow(selectMarkers), N.homoz))
}
```

Apply the function to every row of intros_sub data.frame
```{r}
#extract all of the nested first components of the list components:
comp.list = apply(intros_sub,1,compare_SNPs_in_intros_nohets)
nNIL_compare = lapply(comp.list, function(x) x[[1]])
nNIL_compare = do.call(rbind, nNIL_compare)
colnames(nNIL_compare) = c(colnames(founder_calls_iupac)[-c(1:3)])
#extract all of the nested 2nd components of the list components:
n.SNPs = lapply(comp.list, function(x) x[[2]])
n.SNPs = do.call(c, n.SNPs)
#extract all of the nested 3rd components of the list components:
N.homoz = lapply(comp.list, function(x) x[[3]])
N.homoz = do.call(c, N.homoz)
intros.info = cbind(intros_sub, nNIL_compare)
intros.info$N.SNPs = n.SNPs
intros.info$N.homoz = N.homoz
intros.info$perc.homoz = intros.info$N.homoz/intros.info$N.SNPs
```


Find best match over 0.8 for each introgression  
```{r}
best.matches = apply(nNIL_compare, 1, function(x) colnames(nNIL_compare)[which.max(x)])
matches.80 = apply(nNIL_compare, 1, function(x) x[which.max(x)] > 0.8)
#matches with missing values return logical(0), convert these to FALSE
matches.80 = unlist(lapply(matches.80, function(x) ifelse(length(x) == 0, F, x)))
best.matches[!matches.80]= NA
intros.info$best.matches = unlist(best.matches)
```


Parse the pedigree donor from the line name, fix up donor names
```{r}
intros.info = intros.info |>
  separate_wider_delim(cols = Line, delim = "/", names = c("ped.donor", "suffix"), cols_remove = F) |>
  mutate(ped.donor = ifelse(ped.donor == "MO17", "Mo17", ped.donor),
         ped.donor = ifelse(ped.donor == "KI3", "Ki3", ped.donor),
         best.matches = ifelse(best.matches == "KI3", "Ki3", best.matches),
         ped.match = ped.donor==best.matches)
```

Check that all ped.donor names match hapmap names
```{r}
unique(intros.info$ped.donor)[!unique(intros.info$ped.donor) %in% intros.info$best.matches]
```

```{r}
unique(intros.info$best.matches)[!unique(intros.info$best.matches) %in% intros.info$ped.donor]
```
Diagnose the matches to B73. Hypothesis is that these are either small introgression blocks or highly heterozygous blocks:
```{r}
intros.info |>
  mutate(GROUP = case_when(
    is.na(best.matches) ~ "NA",
    best.matches == "B73" ~ "B73",
    best.matches == ped.donor ~ "CORRECT",
    best.matches != ped.donor ~ "WRONG"
  )) |>
  group_by(GROUP) |>
  summarise(N.blocks = n(), min.N = min(N.SNPs), mean.N = mean(N.SNPs), max.N = max(N.SNPs),
          min.perc.homoz = min(perc.homoz, na.rm = T), mean.perc.homoz = mean(perc.homoz, na.rm = T), max.perc.homoz = max(perc.homoz, na.rm = T),
          min.N.homoz = min(N.homoz), mean.N.homoz = mean(N.homoz), max.N.homoz = max(N.homoz))
```
Blocks that match B73 are on average smaller than other blocks.  
To be more certain about the founder matches of introgression blocks, apply the following filter rule:  
N.homoz >= 50

```{r}
intros.info.filter = intros.info |>
  filter(N.homoz >= 50) 
intros.info.filter |>
  mutate(GROUP = case_when(
    is.na(best.matches) ~ "NA",
    best.matches == "B73" ~ "B73",
    best.matches == ped.donor ~ "CORRECT",
    best.matches != ped.donor ~ "WRONG"
  )) |>
  group_by(GROUP) |>
  summarise(N.blocks = n(), min.N = min(N.SNPs), mean.N = mean(N.SNPs), max.N = max(N.SNPs),
          min.perc.homoz = min(perc.homoz), mean.perc.homoz = mean(perc.homoz), max.perc.homoz = max(perc.homoz),
          min.N.homoz = min(N.homoz), mean.N.homoz = mean(N.homoz), max.N.homoz = max(N.homoz))
```

Still one B73 and some NAs, but we expect some of these are real problems. So go with this level of filtering.  

SUmmarize number of introgressions over Line and best.matches after filtering
```{r}
intros.info.filter|> group_by(Line, best.matches) |>
  summarize(N.intros = n())
```
Summarize over nNILs the best matches. Do this both for the original set of all called introgressions and also only for filtered introgressions.
```{r}
mismatch.by.NIL = intros.info |>
  group_by(Line, ped.donor) |>
  summarize(N.blocks = n(), N.mismatch.blocks= sum(! ped.match, na.rm = T), N.NA.blocks = sum(is.na(ped.match)), N.donor.matches = sum(!is.na(unique(best.matches))), best.matches = paste(unique(best.matches), sep = "/", collapse = "/")) |>
  mutate(best.matches = sub("NA/|/NA", "", best.matches))

mismatch.by.NIL.filtered = intros.info.filter |>
  group_by(Line, ped.donor) |>
  summarize(N.blocks = n(), N.mismatch.blocks= sum(! ped.match, na.rm = T), N.NA.blocks = sum(is.na(ped.match)), N.donor.matches = sum(!is.na(unique(best.matches))), best.matches = paste(unique(best.matches), sep = "/", collapse = "/")) |>
  mutate(best.matches = sub("NA/|/NA", "", best.matches))
```

How many NILs have at least one mismatched introgression after filtering?
```{r}
mismatch.by.NIL.filtered |>
  filter(N.mismatch.blocks > 0) |>
  nrow()
```


How many NILs match more than one donor after filtering?
```{r}
mismatch.by.NIL.filtered |>
  filter(N.donor.matches > 1) |>
  nrow()
```
How many NILs have no certain matches (all blocks have NA donor match) after filtering?
```{r}
mismatch.by.NIL.filtered |>
  filter(N.donor.matches == 0 & N.mismatch.blocks == 0) |>
  nrow()
```
Save files with details of individual introgressions and their match probabilities before filtering
```{r}
write.csv(intros.info, file = paste0(base.path, "nNIL_data_supplement/File_S21.Individual_Introgressions_gbs_donor_matches.csv"), row.names = T, quote = F)
```

Save the file with details of line introgression donor matches before filtering
```{r}
write.csv(mismatch.by.NIL, file = paste0(base.path, "Output/nNIL_donor_match_summary_before_filtering.csv"), row.names = T, quote = F)
```

Save the file with details of line introgression donor matches after filtering
```{r}
write.csv(mismatch.by.NIL.filtered, file = paste0(base.path, "nNIL_data_supplement/File_S22.filtered_nNIL_donor_match_summary.csv"), row.names = F, quote = F)
```




